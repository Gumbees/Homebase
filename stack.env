# Homebase Environment Configuration
# Copy this file to stack.env and fill in your actual values

# =============================================================================
# DATABASE CONFIGURATION (REQUIRED)
# =============================================================================

# PostgreSQL database connection string
# Format: postgresql://username:password@host:port/database_name
# For Docker Compose: postgresql://homebase:homebase@db:5432/homebase
# For local PostgreSQL: postgresql://homebase:homebase@localhost:5432/homebase
DATABASE_URL=postgresql://homebase:homebase@db:5432/homebase

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Flask session secret key - use a long, random string for production
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
SESSION_SECRET=your_secure_random_secret_key_here_change_in_production

# =============================================================================
# MCP SERVER CONFIGURATION
# =============================================================================

# MCP (Model Context Protocol) Server URL
# For Docker Compose: http://mcp-server:8080
# For local development: http://localhost:8080
MCP_SERVER_URL=http://mcp-server:8080

# =============================================================================
# AI SERVICE API KEYS (OPTIONAL)
# =============================================================================

# OpenAI API Configuration
# Get your API key from: https://platform.openai.com/api-keys
# Used for GPT-4 Vision processing of receipts and images
OPENAI_API_KEY=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

# Anthropic Claude API Configuration  
# Get your API key from: https://console.anthropic.com/
# Used for Claude-3.5 Sonnet processing (recommended for best results)
ANTHROPIC_API_KEY=y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

# =============================================================================
# LOCAL AI CONFIGURATION (OPTIONAL)
# =============================================================================

# LLM Studio Endpoint for local AI processing
# Default endpoint for LLM Studio running locally
# Allows offline processing without external API calls
LLM_STUDIO_ENDPOINT=http://localhost:1234

# =============================================================================
# APPLICATION CONFIGURATION (OPTIONAL)
# =============================================================================

# Flask environment mode
# Options: development, production
FLASK_ENV=development

# Enable debug mode (development only)
# Set to false in production
FLASK_DEBUG=true

# Application port (if running without Docker)
PORT=5000

# =============================================================================
# DOCKER COMPOSE OVERRIDES (OPTIONAL)
# =============================================================================

# Override PostgreSQL database settings for Docker Compose
# These are already configured in docker-compose.yml but can be overridden here
# POSTGRES_USER=homebase
# POSTGRES_PASSWORD=homebase
# POSTGRES_DB=homebase

# =============================================================================
# LOGGING CONFIGURATION (OPTIONAL)
# =============================================================================

# Log level for the application
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Maximum log file size in MB
LOG_MAX_SIZE=10

# Number of log backup files to keep
LOG_BACKUP_COUNT=5

# =============================================================================
# AI PROCESSING LIMITS (OPTIONAL)
# =============================================================================

# Maximum AI evaluations per day (rate limiting)
AI_DAILY_LIMIT=30

# AI processing timeout in seconds
AI_TIMEOUT=300

# Default AI provider preference
# Options: claude, openai, llm_studio
DEFAULT_AI_PROVIDER=claude

# =============================================================================
# FILE UPLOAD CONFIGURATION (OPTIONAL)
# =============================================================================

# Maximum file size for uploads in MB
MAX_UPLOAD_SIZE=16

# Allowed file extensions for receipt uploads
ALLOWED_EXTENSIONS=jpg,jpeg,png,pdf

# =============================================================================
# NOTES
# =============================================================================

# 1. At minimum, you need to configure DATABASE_URL and SESSION_SECRET
# 2. For AI functionality, configure at least one AI provider (Claude recommended)
# 3. All other settings have sensible defaults and are optional
# 4. Never commit your actual stack.env file to version control
# 5. Generate secure random keys for production deployments
# 6. Test your configuration with: python -c "import os; print('Config loaded')" after setting up

# =============================================================================
# QUICK START CONFIGURATION
# =============================================================================

# For a minimal working setup, uncomment and configure these variables:
# DATABASE_URL=postgresql://homebase:homebase@db:5432/homebase
# SESSION_SECRET=generate_a_secure_random_key_here
# ANTHROPIC_API_KEY=your_claude_api_key_for_best_ai_results
# MCP_SERVER_URL=http://mcp-server:8080 